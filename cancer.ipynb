{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivavarma11/Cancer-classification-thorough-biomarker-identification/blob/main/cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFyGMNEsF4cI",
        "outputId": "b333233d-21fe-44be-d404-b3e4186c4c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (62, 2000)\n",
            "Selected informative genes indices: [ 357 1555 1129 1575  105   68 1505 1989  664 1449]\n",
            "Reduced dataset shape: (62, 10)\n",
            "Generation 1: Best fitness score = 0.9355\n",
            "Generation 2: Best fitness score = 0.9355\n",
            "Generation 3: Best fitness score = 0.9516\n",
            "Generation 4: Best fitness score = 0.9355\n",
            "Generation 5: Best fitness score = 0.9355\n",
            "Generation 6: Best fitness score = 0.9516\n",
            "Generation 7: Best fitness score = 0.9355\n",
            "Generation 8: Best fitness score = 0.9516\n",
            "Generation 9: Best fitness score = 0.9516\n",
            "Generation 10: Best fitness score = 0.9516\n",
            "Generation 11: Best fitness score = 0.9516\n",
            "Generation 12: Best fitness score = 0.9516\n",
            "Generation 13: Best fitness score = 0.9516\n",
            "Generation 14: Best fitness score = 0.9516\n",
            "Generation 15: Best fitness score = 0.9516\n",
            "Generation 16: Best fitness score = 0.9516\n",
            "Generation 17: Best fitness score = 0.9516\n",
            "Generation 18: Best fitness score = 0.9516\n",
            "Generation 19: Best fitness score = 0.9516\n",
            "Generation 20: Best fitness score = 0.9516\n",
            "Generation 21: Best fitness score = 0.9516\n",
            "Generation 22: Best fitness score = 0.9516\n",
            "Generation 23: Best fitness score = 0.9516\n",
            "Generation 24: Best fitness score = 0.9516\n",
            "Generation 25: Best fitness score = 0.9516\n",
            "Generation 26: Best fitness score = 0.9516\n",
            "Generation 27: Best fitness score = 0.9516\n",
            "Generation 28: Best fitness score = 0.9516\n",
            "Generation 29: Best fitness score = 0.9516\n",
            "Generation 30: Best fitness score = 0.9516\n",
            "Generation 31: Best fitness score = 0.9516\n",
            "Generation 32: Best fitness score = 0.9516\n",
            "Generation 33: Best fitness score = 0.9516\n",
            "Generation 34: Best fitness score = 0.9516\n",
            "Generation 35: Best fitness score = 0.9516\n",
            "Generation 36: Best fitness score = 0.9516\n",
            "Generation 37: Best fitness score = 0.9516\n",
            "Generation 38: Best fitness score = 0.9516\n",
            "Generation 39: Best fitness score = 0.9516\n",
            "Generation 40: Best fitness score = 0.9516\n",
            "Generation 41: Best fitness score = 0.9516\n",
            "Generation 42: Best fitness score = 0.9516\n",
            "Generation 43: Best fitness score = 0.9516\n",
            "Generation 44: Best fitness score = 0.9516\n",
            "Generation 45: Best fitness score = 0.9516\n",
            "Generation 46: Best fitness score = 0.9516\n",
            "Generation 47: Best fitness score = 0.9516\n",
            "Generation 48: Best fitness score = 0.9516\n",
            "Generation 49: Best fitness score = 0.9516\n",
            "Generation 50: Best fitness score = 0.9516\n",
            "Best gene indices after GA: [0, 1, 2, 4, 5, 7, 9]\n",
            "Final selected gene expression shape: (62, 7)\n",
            "Final Classification Accuracy: 0.9516129032258065\n",
            "Confusion Matrix:\n",
            " [[31  0]\n",
            " [ 3 28]]\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from scipy.spatial.distance import mahalanobis\n",
        "import random\n",
        "\n",
        "# Step 1: Simulate Gene Expression Dataset\n",
        "# Create a synthetic dataset with 2000 genes and 62 samples (as in the Colon dataset)\n",
        "np.random.seed(42)\n",
        "data, labels = make_classification(n_samples=62, n_features=2000, n_informative=10,\n",
        "                                   n_classes=2, random_state=42)\n",
        "\n",
        "print(\"Initial dataset shape:\", data.shape)\n",
        "\n",
        "# Step 2: Feature Selection Using Mutual Information (mRMRe)\n",
        "def select_informative_genes(data, labels, top_k=10):\n",
        "    mi_scores = mutual_info_classif(data, labels)\n",
        "    top_gene_indices = mi_scores.argsort()[-top_k:]\n",
        "    return data[:, top_gene_indices], top_gene_indices\n",
        "\n",
        "selected_data, selected_gene_indices = select_informative_genes(data, labels, top_k=10)\n",
        "print(\"Selected informative genes indices:\", selected_gene_indices)\n",
        "print(\"Reduced dataset shape:\", selected_data.shape)\n",
        "\n",
        "# Step 3: Genetic Algorithm for Optimal Gene Selection\n",
        "def initialize_population(size, num_features):\n",
        "    return np.random.randint(2, size=(size, num_features))\n",
        "\n",
        "\n",
        "def fitness_function(population, data, labels):\n",
        "    scores = []\n",
        "    for individual in population:\n",
        "        selected_features = [i for i, bit in enumerate(individual) if bit == 1]\n",
        "        if not selected_features:\n",
        "            scores.append(0)  # Penalize if no features are selected\n",
        "            continue\n",
        "        reduced_data = data[:, selected_features]\n",
        "        accuracy = evaluate_svm_accuracy(reduced_data, labels)\n",
        "        scores.append(accuracy)\n",
        "    return np.array(scores)\n",
        "\n",
        "\n",
        "def evaluate_svm_accuracy(data, labels):\n",
        "    if data.shape[1] == 0:\n",
        "        return 0\n",
        "    model = SVC(kernel='rbf')\n",
        "    model.fit(data, labels)\n",
        "    predictions = model.predict(data)\n",
        "    return accuracy_score(labels, predictions)\n",
        "\n",
        "\n",
        "def genetic_algorithm(data, labels, num_generations=50, population_size=20, crossover_prob=0.8, mutation_prob=0.1):\n",
        "    num_features = data.shape[1]\n",
        "    population = initialize_population(population_size, num_features)\n",
        "\n",
        "    for generation in range(num_generations):\n",
        "        fitness_scores = fitness_function(population, data, labels)\n",
        "\n",
        "        # Selection based on fitness\n",
        "        selected_indices = np.argsort(fitness_scores)[-int(population_size / 2):]\n",
        "        mating_pool = population[selected_indices]\n",
        "\n",
        "        # Crossover\n",
        "        next_generation = []\n",
        "        while len(next_generation) < population_size:\n",
        "            parent1, parent2 = random.choices(mating_pool, k=2)\n",
        "            if random.random() < crossover_prob:\n",
        "                crossover_point = random.randint(1, num_features - 1)\n",
        "                child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n",
        "                child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n",
        "                next_generation.extend([child1, child2])\n",
        "            else:\n",
        "                next_generation.extend([parent1, parent2])\n",
        "\n",
        "        # Mutation\n",
        "        for individual in next_generation:\n",
        "            if random.random() < mutation_prob:\n",
        "                mutation_point = random.randint(0, num_features - 1)\n",
        "                individual[mutation_point] = 1 - individual[mutation_point]\n",
        "\n",
        "        population = np.array(next_generation[:population_size])\n",
        "\n",
        "        # Display generation info\n",
        "        best_fitness = np.max(fitness_scores)\n",
        "        print(f\"Generation {generation + 1}: Best fitness score = {best_fitness:.4f}\")\n",
        "\n",
        "    # Return the best individual\n",
        "    best_individual_idx = np.argmax(fitness_scores)\n",
        "    return population[best_individual_idx]\n",
        "\n",
        "# Run Genetic Algorithm\n",
        "best_solution = genetic_algorithm(selected_data, labels)\n",
        "selected_features = [i for i, bit in enumerate(best_solution) if bit == 1]\n",
        "print(\"Best gene indices after GA:\", selected_features)\n",
        "print(\"Final selected gene expression shape:\", selected_data[:, selected_features].shape)\n",
        "\n",
        "# Step 4: Classification with SVM\n",
        "final_data = selected_data[:, selected_features]\n",
        "final_model = SVC(kernel='rbf')\n",
        "final_model.fit(final_data, labels)\n",
        "predictions = final_model.predict(final_data)\n",
        "\n",
        "accuracy = accuracy_score(labels, predictions)\n",
        "conf_matrix = confusion_matrix(labels, predictions)\n",
        "\n",
        "print(\"Final Classification Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify and display results for each sample\n",
        "predictions = final_model.predict(final_data)\n",
        "\n",
        "for i, prediction in enumerate(predictions):\n",
        "    result = \"Cancer\" if prediction == 1 else \"Healthy\"\n",
        "    print(f\"Sample {i + 1}: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHhq5RHpG_7e",
        "outputId": "772355ee-b238-4c2d-ca4a-2a1e4236b7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: Healthy\n",
            "Sample 2: Cancer\n",
            "Sample 3: Cancer\n",
            "Sample 4: Healthy\n",
            "Sample 5: Healthy\n",
            "Sample 6: Cancer\n",
            "Sample 7: Healthy\n",
            "Sample 8: Cancer\n",
            "Sample 9: Healthy\n",
            "Sample 10: Healthy\n",
            "Sample 11: Healthy\n",
            "Sample 12: Cancer\n",
            "Sample 13: Cancer\n",
            "Sample 14: Cancer\n",
            "Sample 15: Cancer\n",
            "Sample 16: Healthy\n",
            "Sample 17: Healthy\n",
            "Sample 18: Cancer\n",
            "Sample 19: Healthy\n",
            "Sample 20: Healthy\n",
            "Sample 21: Healthy\n",
            "Sample 22: Cancer\n",
            "Sample 23: Cancer\n",
            "Sample 24: Cancer\n",
            "Sample 25: Healthy\n",
            "Sample 26: Healthy\n",
            "Sample 27: Cancer\n",
            "Sample 28: Cancer\n",
            "Sample 29: Cancer\n",
            "Sample 30: Healthy\n",
            "Sample 31: Cancer\n",
            "Sample 32: Healthy\n",
            "Sample 33: Healthy\n",
            "Sample 34: Cancer\n",
            "Sample 35: Cancer\n",
            "Sample 36: Cancer\n",
            "Sample 37: Cancer\n",
            "Sample 38: Healthy\n",
            "Sample 39: Healthy\n",
            "Sample 40: Healthy\n",
            "Sample 41: Healthy\n",
            "Sample 42: Healthy\n",
            "Sample 43: Cancer\n",
            "Sample 44: Healthy\n",
            "Sample 45: Healthy\n",
            "Sample 46: Healthy\n",
            "Sample 47: Cancer\n",
            "Sample 48: Healthy\n",
            "Sample 49: Healthy\n",
            "Sample 50: Cancer\n",
            "Sample 51: Cancer\n",
            "Sample 52: Healthy\n",
            "Sample 53: Cancer\n",
            "Sample 54: Healthy\n",
            "Sample 55: Healthy\n",
            "Sample 56: Cancer\n",
            "Sample 57: Cancer\n",
            "Sample 58: Healthy\n",
            "Sample 59: Healthy\n",
            "Sample 60: Cancer\n",
            "Sample 61: Healthy\n",
            "Sample 62: Cancer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM classifier for cancer stage prediction\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model for multiclass classification\n",
        "stage_classifier = SVC(kernel='rbf')\n",
        "stage_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "stage_predictions = stage_classifier.predict(X_test)\n",
        "\n",
        "# Show detailed report\n",
        "print(\"Cancer Stage Classification Report:\")\n",
        "unique_classes = np.unique(y_test)\n",
        "target_names = [f\"Stage {stage}\" for stage in unique_classes]\n",
        "print(classification_report(y_test, stage_predictions, target_names=target_names))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps0FKynkHSm9",
        "outputId": "fd56169a-2490-48a7-9574-05ecb596d32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cancer Stage Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage 0       0.78      1.00      0.88         7\n",
            "     Stage 1       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.85        13\n",
            "   macro avg       0.89      0.83      0.84        13\n",
            "weighted avg       0.88      0.85      0.84        13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "# Step 1: Simulate Gene Expression Dataset\n",
        "np.random.seed(42)\n",
        "data, labels = make_classification(n_samples=100, n_features=2000, n_informative=10,\n",
        "                                   n_classes=2, random_state=42)\n",
        "print(\"Initial dataset shape:\", data.shape)\n",
        "\n",
        "# Step 1: Binary Classification (Healthy vs Cancer)\n",
        "def binary_classification(data, labels):\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train SVM for binary classification\n",
        "    binary_model = SVC(kernel='rbf')\n",
        "    binary_model.fit(X_train, y_train)\n",
        "    binary_predictions = binary_model.predict(X_test)\n",
        "\n",
        "    # Display results\n",
        "    accuracy = accuracy_score(y_test, binary_predictions)\n",
        "    print(\"Binary Classification (Healthy vs Cancer) Accuracy:\", accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, binary_predictions))\n",
        "\n",
        "    return binary_model, X_test, binary_predictions, y_test\n",
        "\n",
        "binary_model, X_test, binary_predictions, y_test = binary_classification(data, labels)\n",
        "\n",
        "# Step 2: Simulate Cancer Stages Dataset\n",
        "# Assume stages are labeled as 0 (Stage 0), 1 (Stage I), 2 (Stage II), 3 (Stage III), 4 (Stage IV)\n",
        "np.random.seed(42)\n",
        "stage_labels = np.random.randint(0, 5, size=data.shape[0])\n",
        "\n",
        "# Use only cancer samples for stage classification\n",
        "cancer_indices = np.where(labels == 1)[0]\n",
        "stage_data = data[cancer_indices]\n",
        "stage_labels = stage_labels[cancer_indices]\n",
        "\n",
        "# Multiclass Cancer Stage Prediction\n",
        "def cancer_stage_classification(stage_data, stage_labels):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(stage_data, stage_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train SVM for multiclass classification\n",
        "    stage_classifier = SVC(kernel='rbf')\n",
        "    stage_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    stage_predictions = stage_classifier.predict(X_test)\n",
        "\n",
        "    # Dynamic target names based on available classes\n",
        "    unique_classes = sorted(np.unique(y_test))\n",
        "    target_names = [f\"Stage {stage}\" for stage in unique_classes]\n",
        "    class_to_name_mapping = dict(zip(unique_classes, target_names))\n",
        "\n",
        "    # Display classification report with zero_division parameter to handle precision warnings\n",
        "    print(\"Cancer Stage Classification Report:\")\n",
        "    print(classification_report(y_test, stage_predictions, target_names=target_names, zero_division=1))\n",
        "\n",
        "    return stage_classifier, class_to_name_mapping\n",
        "\n",
        "# Run stage classification only for detected cancer cases\n",
        "stage_classifier, class_to_name_mapping = cancer_stage_classification(stage_data, stage_labels)\n",
        "\n",
        "# Final Prediction Integration\n",
        "print(\"\\nFinal Predictions:\")\n",
        "for i in range(len(X_test)):\n",
        "    if binary_predictions[i] == 0:\n",
        "        print(f\"Sample {i + 1}: Healthy\")\n",
        "    else:\n",
        "        stage_prediction = stage_classifier.predict(X_test[i].reshape(1, -1))\n",
        "        stage_name = class_to_name_mapping.get(stage_prediction[0], \"Unknown Stage\")\n",
        "        print(f\"Sample {i + 1}: Cancer - Predicted Stage: {stage_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm61mJqlIBhW",
        "outputId": "81f2564b-2727-444b-8a85-0f1d079c4375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (100, 2000)\n",
            "Binary Classification (Healthy vs Cancer) Accuracy: 0.6\n",
            "Confusion Matrix:\n",
            " [[8 2]\n",
            " [6 4]]\n",
            "Cancer Stage Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Stage 0       1.00      0.00      0.00         3\n",
            "     Stage 1       1.00      0.00      0.00         3\n",
            "     Stage 3       0.20      1.00      0.33         2\n",
            "     Stage 4       1.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.20        10\n",
            "   macro avg       0.80      0.25      0.08        10\n",
            "weighted avg       0.84      0.20      0.07        10\n",
            "\n",
            "\n",
            "Final Predictions:\n",
            "Sample 1: Cancer - Predicted Stage: Stage 3\n",
            "Sample 2: Healthy\n",
            "Sample 3: Healthy\n",
            "Sample 4: Healthy\n",
            "Sample 5: Healthy\n",
            "Sample 6: Healthy\n",
            "Sample 7: Healthy\n",
            "Sample 8: Cancer - Predicted Stage: Stage 4\n",
            "Sample 9: Cancer - Predicted Stage: Stage 3\n",
            "Sample 10: Cancer - Predicted Stage: Stage 3\n",
            "Sample 11: Healthy\n",
            "Sample 12: Healthy\n",
            "Sample 13: Healthy\n",
            "Sample 14: Healthy\n",
            "Sample 15: Healthy\n",
            "Sample 16: Healthy\n",
            "Sample 17: Healthy\n",
            "Sample 18: Cancer - Predicted Stage: Stage 3\n",
            "Sample 19: Cancer - Predicted Stage: Stage 3\n",
            "Sample 20: Healthy\n"
          ]
        }
      ]
    }
  ]
}